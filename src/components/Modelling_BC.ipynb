{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c89217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "############################################## PREPROCESSING ##############################################\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "################################################# METRICS #################################################\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "################################### MODEL SELECTION & OPTIMIZATION ########################################\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "######################################### DECISION TREES PLOTS ############################################\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6285da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(r\"C:\\Users\\pedro\\OneDrive\\Desktop\\DSProject Folder\\src\\Financial Data 14-18\\Int DFs\\df_mod.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ec67281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19718, 26)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b983c229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Effect of forex changes on cash</th>\n",
       "      <th>SG&amp;A Expenses Growth</th>\n",
       "      <th>Receivables Turnover</th>\n",
       "      <th>5Y Revenue Growth (per Share)</th>\n",
       "      <th>3Y Shareholders Equity Growth (per Share)</th>\n",
       "      <th>Issuance (buybacks) of shares</th>\n",
       "      <th>eBITperRevenue</th>\n",
       "      <th>Net cash flow / Change in cash</th>\n",
       "      <th>priceSalesRatio</th>\n",
       "      <th>SG&amp;A to Revenue</th>\n",
       "      <th>...</th>\n",
       "      <th>Operating Cash Flow</th>\n",
       "      <th>3Y Net Income Growth (per Share)</th>\n",
       "      <th>returnOnCapitalEmployed</th>\n",
       "      <th>Tangible Book Value per Share</th>\n",
       "      <th>Investing Cash flow</th>\n",
       "      <th>Gross Margin</th>\n",
       "      <th>PFCF ratio</th>\n",
       "      <th>5Y Operating CF Growth (per Share)</th>\n",
       "      <th>Class</th>\n",
       "      <th>Following Year Price Variation [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.564869e+07</td>\n",
       "      <td>1.73130</td>\n",
       "      <td>6.48354</td>\n",
       "      <td>0.06600</td>\n",
       "      <td>0.79730</td>\n",
       "      <td>1.767840e+06</td>\n",
       "      <td>0.050221</td>\n",
       "      <td>4.463169e+08</td>\n",
       "      <td>0.095727</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>...</td>\n",
       "      <td>5.267456e+08</td>\n",
       "      <td>0.25206</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.49390</td>\n",
       "      <td>-6.866936e+08</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>1.3589</td>\n",
       "      <td>0.11996</td>\n",
       "      <td>0</td>\n",
       "      <td>-25.512193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.02340</td>\n",
       "      <td>90.79370</td>\n",
       "      <td>0.10380</td>\n",
       "      <td>0.07890</td>\n",
       "      <td>-4.130000e+08</td>\n",
       "      <td>0.027578</td>\n",
       "      <td>1.630000e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1545</td>\n",
       "      <td>...</td>\n",
       "      <td>3.573000e+09</td>\n",
       "      <td>0.18920</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>25.72400</td>\n",
       "      <td>-4.771000e+09</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>14.6302</td>\n",
       "      <td>0.09370</td>\n",
       "      <td>1</td>\n",
       "      <td>33.118297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.00600</td>\n",
       "      <td>27.17690</td>\n",
       "      <td>-0.02900</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.321700e+07</td>\n",
       "      <td>0.026436</td>\n",
       "      <td>1.695400e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2570</td>\n",
       "      <td>...</td>\n",
       "      <td>7.020460e+08</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1062</td>\n",
       "      <td>134.78500</td>\n",
       "      <td>-3.649240e+08</td>\n",
       "      <td>0.2869</td>\n",
       "      <td>17.2736</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>1</td>\n",
       "      <td>2.752291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.920000e+07</td>\n",
       "      <td>-0.02200</td>\n",
       "      <td>12.22500</td>\n",
       "      <td>0.05670</td>\n",
       "      <td>0.02170</td>\n",
       "      <td>-1.637200e+09</td>\n",
       "      <td>0.168072</td>\n",
       "      <td>1.259000e+08</td>\n",
       "      <td>1.553911</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>...</td>\n",
       "      <td>2.541000e+09</td>\n",
       "      <td>0.01770</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>15.42900</td>\n",
       "      <td>-5.618000e+08</td>\n",
       "      <td>0.3557</td>\n",
       "      <td>17.6902</td>\n",
       "      <td>0.08280</td>\n",
       "      <td>1</td>\n",
       "      <td>12.897715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.760000e+08</td>\n",
       "      <td>0.01610</td>\n",
       "      <td>20.39100</td>\n",
       "      <td>0.09610</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-3.833000e+09</td>\n",
       "      <td>0.145332</td>\n",
       "      <td>-4.720000e+08</td>\n",
       "      <td>1.299472</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>...</td>\n",
       "      <td>7.739000e+09</td>\n",
       "      <td>-0.00840</td>\n",
       "      <td>0.3752</td>\n",
       "      <td>15.32700</td>\n",
       "      <td>-9.960000e+08</td>\n",
       "      <td>0.2413</td>\n",
       "      <td>19.2150</td>\n",
       "      <td>0.03770</td>\n",
       "      <td>1</td>\n",
       "      <td>13.980937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-2.230000e+08</td>\n",
       "      <td>-0.02560</td>\n",
       "      <td>6.74490</td>\n",
       "      <td>-0.04940</td>\n",
       "      <td>-0.06070</td>\n",
       "      <td>-1.700000e+09</td>\n",
       "      <td>0.094177</td>\n",
       "      <td>-9.910000e+08</td>\n",
       "      <td>1.644111</td>\n",
       "      <td>0.2470</td>\n",
       "      <td>...</td>\n",
       "      <td>3.562000e+09</td>\n",
       "      <td>-0.13540</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>13.71900</td>\n",
       "      <td>-1.642000e+09</td>\n",
       "      <td>0.3679</td>\n",
       "      <td>31.6718</td>\n",
       "      <td>-0.09250</td>\n",
       "      <td>1</td>\n",
       "      <td>23.809818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.08500</td>\n",
       "      <td>205.20500</td>\n",
       "      <td>0.01770</td>\n",
       "      <td>-0.05190</td>\n",
       "      <td>-9.390000e+08</td>\n",
       "      <td>0.349971</td>\n",
       "      <td>1.460000e+08</td>\n",
       "      <td>3.319691</td>\n",
       "      <td>0.1035</td>\n",
       "      <td>...</td>\n",
       "      <td>4.663000e+09</td>\n",
       "      <td>0.15880</td>\n",
       "      <td>0.1948</td>\n",
       "      <td>8.67300</td>\n",
       "      <td>1.770000e+08</td>\n",
       "      <td>0.4143</td>\n",
       "      <td>21.6402</td>\n",
       "      <td>0.07260</td>\n",
       "      <td>1</td>\n",
       "      <td>23.865489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.788960e+07</td>\n",
       "      <td>-0.00760</td>\n",
       "      <td>11.93360</td>\n",
       "      <td>0.15340</td>\n",
       "      <td>0.09406</td>\n",
       "      <td>3.131806e+07</td>\n",
       "      <td>0.408287</td>\n",
       "      <td>-7.570785e+08</td>\n",
       "      <td>2.252915</td>\n",
       "      <td>0.2883</td>\n",
       "      <td>...</td>\n",
       "      <td>7.052460e+09</td>\n",
       "      <td>0.05698</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.98010</td>\n",
       "      <td>-1.790462e+09</td>\n",
       "      <td>0.6635</td>\n",
       "      <td>6.7470</td>\n",
       "      <td>0.19388</td>\n",
       "      <td>0</td>\n",
       "      <td>-22.605312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.943980e+05</td>\n",
       "      <td>0.34600</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.45210</td>\n",
       "      <td>0.12170</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.214357</td>\n",
       "      <td>8.484990e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3379</td>\n",
       "      <td>...</td>\n",
       "      <td>1.015584e+08</td>\n",
       "      <td>0.28460</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.88800</td>\n",
       "      <td>-1.740287e+07</td>\n",
       "      <td>0.5172</td>\n",
       "      <td>6.8263</td>\n",
       "      <td>0.27070</td>\n",
       "      <td>1</td>\n",
       "      <td>65.373665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.320000e+08</td>\n",
       "      <td>-0.01442</td>\n",
       "      <td>15.78346</td>\n",
       "      <td>0.03482</td>\n",
       "      <td>0.07494</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.134957</td>\n",
       "      <td>-1.610000e+08</td>\n",
       "      <td>12.993151</td>\n",
       "      <td>0.1565</td>\n",
       "      <td>...</td>\n",
       "      <td>2.140000e+09</td>\n",
       "      <td>0.03054</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>20.10842</td>\n",
       "      <td>-3.490000e+08</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>22.0915</td>\n",
       "      <td>0.04848</td>\n",
       "      <td>1</td>\n",
       "      <td>2.065963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Effect of forex changes on cash  SG&A Expenses Growth  \\\n",
       "0                    -1.564869e+07               1.73130   \n",
       "1                     0.000000e+00               0.02340   \n",
       "2                     0.000000e+00              -0.00600   \n",
       "3                    -2.920000e+07              -0.02200   \n",
       "4                    -3.760000e+08               0.01610   \n",
       "5                    -2.230000e+08              -0.02560   \n",
       "6                     0.000000e+00               0.08500   \n",
       "7                     3.788960e+07              -0.00760   \n",
       "8                     6.943980e+05               0.34600   \n",
       "9                    -1.320000e+08              -0.01442   \n",
       "\n",
       "   Receivables Turnover  5Y Revenue Growth (per Share)  \\\n",
       "0               6.48354                        0.06600   \n",
       "1              90.79370                        0.10380   \n",
       "2              27.17690                       -0.02900   \n",
       "3              12.22500                        0.05670   \n",
       "4              20.39100                        0.09610   \n",
       "5               6.74490                       -0.04940   \n",
       "6             205.20500                        0.01770   \n",
       "7              11.93360                        0.15340   \n",
       "8               0.00000                        0.45210   \n",
       "9              15.78346                        0.03482   \n",
       "\n",
       "   3Y Shareholders Equity Growth (per Share)  Issuance (buybacks) of shares  \\\n",
       "0                                    0.79730                   1.767840e+06   \n",
       "1                                    0.07890                  -4.130000e+08   \n",
       "2                                    0.00000                   3.321700e+07   \n",
       "3                                    0.02170                  -1.637200e+09   \n",
       "4                                    0.00000                  -3.833000e+09   \n",
       "5                                   -0.06070                  -1.700000e+09   \n",
       "6                                   -0.05190                  -9.390000e+08   \n",
       "7                                    0.09406                   3.131806e+07   \n",
       "8                                    0.12170                   0.000000e+00   \n",
       "9                                    0.07494                   0.000000e+00   \n",
       "\n",
       "   eBITperRevenue  Net cash flow / Change in cash  priceSalesRatio  \\\n",
       "0        0.050221                    4.463169e+08         0.095727   \n",
       "1        0.027578                    1.630000e+08         0.000000   \n",
       "2        0.026436                    1.695400e+07         0.000000   \n",
       "3        0.168072                    1.259000e+08         1.553911   \n",
       "4        0.145332                   -4.720000e+08         1.299472   \n",
       "5        0.094177                   -9.910000e+08         1.644111   \n",
       "6        0.349971                    1.460000e+08         3.319691   \n",
       "7        0.408287                   -7.570785e+08         2.252915   \n",
       "8        0.214357                    8.484990e+07         0.000000   \n",
       "9        0.134957                   -1.610000e+08        12.993151   \n",
       "\n",
       "   SG&A to Revenue  ...  Operating Cash Flow  \\\n",
       "0           0.0922  ...         5.267456e+08   \n",
       "1           0.1545  ...         3.573000e+09   \n",
       "2           0.2570  ...         7.020460e+08   \n",
       "3           0.1940  ...         2.541000e+09   \n",
       "4           0.0874  ...         7.739000e+09   \n",
       "5           0.2470  ...         3.562000e+09   \n",
       "6           0.1035  ...         4.663000e+09   \n",
       "7           0.2883  ...         7.052460e+09   \n",
       "8           0.3379  ...         1.015584e+08   \n",
       "9           0.1565  ...         2.140000e+09   \n",
       "\n",
       "   3Y Net Income Growth (per Share)  returnOnCapitalEmployed  \\\n",
       "0                           0.25206                   0.0000   \n",
       "1                           0.18920                   0.0859   \n",
       "2                           0.00000                   0.1062   \n",
       "3                           0.01770                   0.1041   \n",
       "4                          -0.00840                   0.3752   \n",
       "5                          -0.13540                   0.0376   \n",
       "6                           0.15880                   0.1948   \n",
       "7                           0.05698                   0.2515   \n",
       "8                           0.28460                   0.0000   \n",
       "9                           0.03054                   0.0433   \n",
       "\n",
       "   Tangible Book Value per Share  Investing Cash flow  Gross Margin  \\\n",
       "0                        4.49390        -6.866936e+08        0.2487   \n",
       "1                       25.72400        -4.771000e+09        0.2057   \n",
       "2                      134.78500        -3.649240e+08        0.2869   \n",
       "3                       15.42900        -5.618000e+08        0.3557   \n",
       "4                       15.32700        -9.960000e+08        0.2413   \n",
       "5                       13.71900        -1.642000e+09        0.3679   \n",
       "6                        8.67300         1.770000e+08        0.4143   \n",
       "7                        0.98010        -1.790462e+09        0.6635   \n",
       "8                        0.88800        -1.740287e+07        0.5172   \n",
       "9                       20.10842        -3.490000e+08        0.3000   \n",
       "\n",
       "   PFCF ratio  5Y Operating CF Growth (per Share)  Class  \\\n",
       "0      1.3589                             0.11996      0   \n",
       "1     14.6302                             0.09370      1   \n",
       "2     17.2736                             0.11640      1   \n",
       "3     17.6902                             0.08280      1   \n",
       "4     19.2150                             0.03770      1   \n",
       "5     31.6718                            -0.09250      1   \n",
       "6     21.6402                             0.07260      1   \n",
       "7      6.7470                             0.19388      0   \n",
       "8      6.8263                             0.27070      1   \n",
       "9     22.0915                             0.04848      1   \n",
       "\n",
       "   Following Year Price Variation [%]  \n",
       "0                          -25.512193  \n",
       "1                           33.118297  \n",
       "2                            2.752291  \n",
       "3                           12.897715  \n",
       "4                           13.980937  \n",
       "5                           23.809818  \n",
       "6                           23.865489  \n",
       "7                          -22.605312  \n",
       "8                           65.373665  \n",
       "9                            2.065963  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be22fd2e",
   "metadata": {},
   "source": [
    "Apply Train Test Split so we save a portion of unseen data to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "531d543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Following Year Price Variation [%]', 'Class'])\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11caa58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82db7b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15774, 24), (3944, 24), (15774,), (3944,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6455a378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model (X, y, model):\n",
    "\n",
    "    score_train = []\n",
    "    score_val = []\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=99) # Because it's a classification problem. In the regression problem we will use KFold\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),  #Scale the data\n",
    "        ('clf', model) #Model is passed as an argument (KNN, Decision Tree, MLP, etc)\n",
    "    ])\n",
    "    #Cross Validation\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_t, X_v = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_t, y_v = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        pipe.fit(X_t, y_t)\n",
    "\n",
    "        pred_train = pipe.predict(X_t)\n",
    "        pred_val = pipe.predict(X_v)\n",
    "\n",
    "        score_train.append(f1_score(y_t, pred_train))  #Using F1-score as a metric because its a classification problem\n",
    "        score_val.append(f1_score(y_v, pred_val))\n",
    "    \n",
    "    avg_train = round(np.mean(score_train), 3)\n",
    "    avg_val = round(np.mean(score_val), 3)\n",
    "    std_train = round(np.std(score_train), 2)\n",
    "    std_val = round(np.std(score_val), 2) \n",
    "\n",
    "    return avg_train, std_train, avg_val, std_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31db4860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_assessment(X, y , **models):\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        avg_train, std_train, avg_val, std_val = apply_model(X, y, model)\n",
    "        results[name] = {\n",
    "            \"Train\": f\"{avg_train:.3f} +/- {std_train:.2f}\",\n",
    "            \"Validation\": f\"{avg_val:.3f} +/- {std_val:.2f}\"\n",
    "        }\n",
    "    return pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec00d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################# MODELS ##################################################\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c3533e",
   "metadata": {},
   "source": [
    "Create the dictionary of models to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9a70e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Neural Network\": MLPClassifier(hidden_layer_sizes=(50,50), max_iter=500, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ad8a370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Train      Validation\n",
      "Random Forest        1.000 +/- 0.00  0.679 +/- 0.00\n",
      "Gradient Boosting    0.729 +/- 0.00  0.691 +/- 0.00\n",
      "Logistic Regression  0.695 +/- 0.00  0.692 +/- 0.00\n",
      "KNN                  0.750 +/- 0.00  0.609 +/- 0.00\n",
      "Neural Network       0.687 +/- 0.02  0.683 +/- 0.01\n"
     ]
    }
   ],
   "source": [
    "results_df = model_assessment(X_train, y_train, **models)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca1c54b",
   "metadata": {},
   "source": [
    "Random Forest sems to be highly overfiited with a perfect score in the training phase and a considerable decrease in the Valiation Phase  \n",
    "Best Models seem to be Gradient Boosting an Logistic Regression. Not overfiited and with the best Validation Scores.  \n",
    "\n",
    "These 2 will move on to Fine Tuning/Model Optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8243702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scipy.stats import uniform, randint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9a9400",
   "metadata": {},
   "source": [
    "Let's use RandomizedSearchCV as GridSearch tests all possible combinations and is very computationally expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37cb4a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "lr = LogisticRegression(max_iter=500, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9d4977",
   "metadata": {},
   "source": [
    "Gradient Boosting (Not sensitive to scalling, tree based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ca897ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': np.float64(0.011413261043943482), 'max_depth': 3, 'n_estimators': 98}\n",
      "0.7064103616384327\n"
     ]
    }
   ],
   "source": [
    "param_dist_gb = {\n",
    "    'n_estimators': randint(50, 300),\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'max_depth': randint(3, 10)\n",
    "}\n",
    "\n",
    "random_search_gb = RandomizedSearchCV(\n",
    "    estimator=gb,\n",
    "    param_distributions=param_dist_gb,\n",
    "    n_iter=50,     # number of random combinations to try\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search_gb.fit(X_train, y_train)\n",
    "print(random_search_gb.best_params_)\n",
    "print(random_search_gb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c8ad07",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec838605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__C': np.float64(0.21584494295802448), 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "0.6960541802339144\n"
     ]
    }
   ],
   "source": [
    "pipeline_tun = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),  #Scale the data\n",
    "    ('classifier', lr)\n",
    "])\n",
    "\n",
    "param_dist_lr = {\n",
    "    'classifier__C': uniform(0.01, 10),           # regularization strength\n",
    "    'classifier__penalty': ['l1', 'l2'],          # type of regularization\n",
    "    'classifier__solver': ['liblinear', 'saga']   # solvers that support l1/l2\n",
    "}\n",
    "\n",
    "random_search_lr = RandomizedSearchCV(\n",
    "    estimator=pipeline_tun,\n",
    "    param_distributions=param_dist_lr,\n",
    "    n_iter=20,     # number of random combinations to try\n",
    "    cv=5, #For each combination of hyperparameters, perform 5-fold cross-validation. Trains on 4 folds and validates on the remaining fold.\n",
    "    scoring='f1', #RS will try to maximize the F1-score\n",
    "    n_jobs=-1, #Controls parallel processing, -1 means using all processors, 1= single processor etc\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search_lr.fit(X_train, y_train)\n",
    "print(random_search_lr.best_params_)\n",
    "print(random_search_lr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b111c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_gb = GradientBoostingClassifier(learning_rate=0.011413261043943482, \n",
    "                                            max_depth= 3,\n",
    "                                            n_estimators= 98,\n",
    "                                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc2fdf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_lr=LogisticRegression(C=0.21584494295802448,\n",
    "                                    penalty= 'l2', \n",
    "                                    solver= 'saga',\n",
    "                                    max_iter=500,  #Not fine tuned but default =100 and LR oftern needs more iterations to converge\n",
    "                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5027392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_final = {\"Gradient Boosting\": final_model_gb,\n",
    "                \"Logistic Regression\": final_model_lr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f456c3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Train      Validation\n",
      "Gradient Boosting    0.713 +/- 0.00  0.707 +/- 0.00\n",
      "Logistic Regression  0.696 +/- 0.00  0.695 +/- 0.00\n"
     ]
    }
   ],
   "source": [
    "fresults_df= model_assessment(X_train, y_train, **models_final)\n",
    "print(fresults_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9122e37e",
   "metadata": {},
   "source": [
    "GB : Very small gap, model generalizes well, there is no overfitting.  \n",
    "\n",
    "LR : Nearly identical. Excellent stability, just slightly less predictive power than Gradient Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2311c3",
   "metadata": {},
   "source": [
    "Save/Export Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58771423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371665d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_model_lr.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(final_model_gb, \"final_model_gb.pkl\")\n",
    "joblib.dump(final_model_lr, \"final_model_lr.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1850ed02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler().fit(X_train)\n",
    "joblib.dump(scaler, \"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4daac13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_data.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump((X_test, y_test), \"test_data.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
